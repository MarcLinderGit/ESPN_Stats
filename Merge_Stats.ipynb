{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>College</th>\n",
       "      <th>Draft_Year</th>\n",
       "      <th>Draft_Round</th>\n",
       "      <th>Draft_Pick_Overall</th>\n",
       "      <th>Draft_Team</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben DiNucci</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#11</td>\n",
       "      <td>QB</td>\n",
       "      <td>11/24/1996</td>\n",
       "      <td>James Madison</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>231</td>\n",
       "      <td>DAL</td>\n",
       "      <td>6' 2</td>\n",
       "      <td>215 lbs</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jarrett Stidham</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#4</td>\n",
       "      <td>QB</td>\n",
       "      <td>8/8/1996</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>133</td>\n",
       "      <td>NE</td>\n",
       "      <td>6' 3</td>\n",
       "      <td>215 lbs</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russell Wilson</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#3</td>\n",
       "      <td>QB</td>\n",
       "      <td>11/29/1988</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>SEA</td>\n",
       "      <td>5' 11</td>\n",
       "      <td>215 lbs</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tyler Badie</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#36</td>\n",
       "      <td>RB</td>\n",
       "      <td>2/7/2000</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>196</td>\n",
       "      <td>BAL</td>\n",
       "      <td>5' 8</td>\n",
       "      <td>197 lbs</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jaleel McLaughlin</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#38</td>\n",
       "      <td>RB</td>\n",
       "      <td>9/13/2000</td>\n",
       "      <td>Youngstown St</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>5' 7</td>\n",
       "      <td>187 lbs</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Caden Sterns</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#30</td>\n",
       "      <td>S</td>\n",
       "      <td>11/2/1999</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>152</td>\n",
       "      <td>DEN</td>\n",
       "      <td>6' 1</td>\n",
       "      <td>207 lbs</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Delarrin Turner-Yell</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#32</td>\n",
       "      <td>S</td>\n",
       "      <td>12/16/1999</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>152</td>\n",
       "      <td>DEN</td>\n",
       "      <td>5' 11</td>\n",
       "      <td>200 lbs</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Wil Lutz</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#16</td>\n",
       "      <td>PK</td>\n",
       "      <td>7/7/1994</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>5' 11</td>\n",
       "      <td>184 lbs</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Riley Dixon</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#9</td>\n",
       "      <td>P</td>\n",
       "      <td>8/24/1993</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>228</td>\n",
       "      <td>DEN</td>\n",
       "      <td>6' 4</td>\n",
       "      <td>221 lbs</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Mitchell Fraboni</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>#48</td>\n",
       "      <td>LS</td>\n",
       "      <td>10/28/1996</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>undrafted</td>\n",
       "      <td>6' 2</td>\n",
       "      <td>223 lbs</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player_Name     Team Number Position   Birthdate        College  \\\n",
       "0            Ben DiNucci  Broncos    #11       QB  11/24/1996  James Madison   \n",
       "1        Jarrett Stidham  Broncos     #4       QB    8/8/1996         Auburn   \n",
       "2         Russell Wilson  Broncos     #3       QB  11/29/1988      Wisconsin   \n",
       "3            Tyler Badie  Broncos    #36       RB    2/7/2000       Missouri   \n",
       "4      Jaleel McLaughlin  Broncos    #38       RB   9/13/2000  Youngstown St   \n",
       "..                   ...      ...    ...      ...         ...            ...   \n",
       "73          Caden Sterns  Broncos    #30        S   11/2/1999          Texas   \n",
       "74  Delarrin Turner-Yell  Broncos    #32        S  12/16/1999       Oklahoma   \n",
       "75              Wil Lutz  Broncos    #16       PK    7/7/1994  Georgia State   \n",
       "76           Riley Dixon  Broncos     #9        P   8/24/1993       Syracuse   \n",
       "77      Mitchell Fraboni  Broncos    #48       LS  10/28/1996  Arizona State   \n",
       "\n",
       "   Draft_Year Draft_Round Draft_Pick_Overall Draft_Team Height   Weight  Age  \n",
       "0        2020           7                231        DAL   6' 2  215 lbs   26  \n",
       "1        2019           4                133         NE   6' 3  215 lbs   27  \n",
       "2        2012           3                 75        SEA  5' 11  215 lbs   34  \n",
       "3        2022           6                196        BAL   5' 8  197 lbs   23  \n",
       "4   undrafted   undrafted          undrafted  undrafted   5' 7  187 lbs   23  \n",
       "..        ...         ...                ...        ...    ...      ...  ...  \n",
       "73       2021           5                152        DEN   6' 1  207 lbs   23  \n",
       "74       2022           5                152        DEN  5' 11  200 lbs   23  \n",
       "75  undrafted   undrafted          undrafted  undrafted  5' 11  184 lbs   29  \n",
       "76       2016           7                228        DEN   6' 4  221 lbs   30  \n",
       "77  undrafted   undrafted          undrafted  undrafted   6' 2  223 lbs   26  \n",
       "\n",
       "[78 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "player_bios = pd.read_csv('player_bio.csv')\n",
    "player_bios.rename(columns={player_bios.columns[0]: 'Player_Name'}, inplace=True)\n",
    "\n",
    "# You can now work with the data using the DataFrame\n",
    "player_bios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Players without Numbers (to be moved to scarper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keondre Coburn  does not have\n",
      "             Player_Name     Team Number Position   Birthdate        College  \\\n",
      "0            Ben DiNucci  Broncos    #11       QB  11/24/1996  James Madison   \n",
      "1        Jarrett Stidham  Broncos     #4       QB    8/8/1996         Auburn   \n",
      "2         Russell Wilson  Broncos     #3       QB  11/29/1988      Wisconsin   \n",
      "3            Tyler Badie  Broncos    #36       RB    2/7/2000       Missouri   \n",
      "4      Jaleel McLaughlin  Broncos    #38       RB   9/13/2000  Youngstown St   \n",
      "..                   ...      ...    ...      ...         ...            ...   \n",
      "73          Caden Sterns  Broncos    #30        S   11/2/1999          Texas   \n",
      "74  Delarrin Turner-Yell  Broncos    #32        S  12/16/1999       Oklahoma   \n",
      "75              Wil Lutz  Broncos    #16       PK    7/7/1994  Georgia State   \n",
      "76           Riley Dixon  Broncos     #9        P   8/24/1993       Syracuse   \n",
      "77      Mitchell Fraboni  Broncos    #48       LS  10/28/1996  Arizona State   \n",
      "\n",
      "   Draft_Year Draft_Round Draft_Pick_Overall Draft_Team Height   Weight  Age  \n",
      "0        2020           7                231        DAL   6' 2  215 lbs   26  \n",
      "1        2019           4                133         NE   6' 3  215 lbs   27  \n",
      "2        2012           3                 75        SEA  5' 11  215 lbs   34  \n",
      "3        2022           6                196        BAL   5' 8  197 lbs   23  \n",
      "4   undrafted   undrafted          undrafted  undrafted   5' 7  187 lbs   23  \n",
      "..        ...         ...                ...        ...    ...      ...  ...  \n",
      "73       2021           5                152        DEN   6' 1  207 lbs   23  \n",
      "74       2022           5                152        DEN  5' 11  200 lbs   23  \n",
      "75  undrafted   undrafted          undrafted  undrafted  5' 11  184 lbs   29  \n",
      "76       2016           7                228        DEN   6' 4  221 lbs   30  \n",
      "77  undrafted   undrafted          undrafted  undrafted   6' 2  223 lbs   26  \n",
      "\n",
      "[78 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the DataFrame and update the \"Position\" and \"Number\" columns\n",
    "for index, row in player_bios.iterrows():\n",
    "    if not row['Number'].startswith('#'):\n",
    "        print(player_bios.at[index, 'Player_Name'], \" does not have\")\n",
    "        player_bios.at[index, 'Position'] = player_bios.at[index, 'Number']\n",
    "        player_bios.at[index, 'Number'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Player_Name     Team Number Position  Birthdate College Draft_Year  \\\n",
      "40  Keondre Coburn  Broncos   None       DT  5/23/2000   Texas       2023   \n",
      "\n",
      "   Draft_Round Draft_Pick_Overall Draft_Team Height   Weight  Age  \n",
      "40           6                194         KC   6' 2  332 lbs   23  \n"
     ]
    }
   ],
   "source": [
    "contain_values = player_bios[player_bios['Player_Name'].str.contains('Keondre Coburn')]\n",
    "print (contain_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'player_bios.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Marc\\Dropbox\\Arbeitsplatz\\03_Coding\\01_Projects\\03_NFL_Stats_ESPN\\Merge_Stats.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Marc/Dropbox/Arbeitsplatz/03_Coding/01_Projects/03_NFL_Stats_ESPN/Merge_Stats.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m player_bios_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mplayer_bios.csv\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Replace with the actual path\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marc/Dropbox/Arbeitsplatz/03_Coding/01_Projects/03_NFL_Stats_ESPN/Merge_Stats.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Read the player_bios file into a DataFrame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Marc/Dropbox/Arbeitsplatz/03_Coding/01_Projects/03_NFL_Stats_ESPN/Merge_Stats.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m player_bios_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(player_bios_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marc/Dropbox/Arbeitsplatz/03_Coding/01_Projects/03_NFL_Stats_ESPN/Merge_Stats.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Create dictionaries to map positions to units\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marc/Dropbox/Arbeitsplatz/03_Coding/01_Projects/03_NFL_Stats_ESPN/Merge_Stats.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m offense_positions \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mQB\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRB\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFB\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWR\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTE\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mG\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mOT\u001b[39m\u001b[39m\"\u001b[39m}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'player_bios.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Define the root directory where you want to search for sub-folders and CSV files\n",
    "root_directory = \"PlayerData\"  # Assuming \"PlayerData\" is in your current working directory\n",
    "\n",
    "# Define the path to the player_bios file\n",
    "player_bios_file = \"player_bios.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the player_bios file into a DataFrame\n",
    "player_bios_df = pd.read_csv(player_bios_file)\n",
    "\n",
    "# Create dictionaries to map positions to units\n",
    "offense_positions = {\"QB\", \"RB\", \"FB\", \"WR\", \"TE\", \"C\", \"G\", \"OT\"}\n",
    "defense_positions = {\"DE\", \"DT\", \"LB\", \"CB\", \"S\"}\n",
    "special_teams_positions = {\"PK\", \"P\", \"LS\"}\n",
    "\n",
    "# Initialize dictionaries to store merged dataframes for each unit\n",
    "merged_dataframes = {\n",
    "    \"Offense\": pd.DataFrame(),\n",
    "    \"Defense\": pd.DataFrame(),\n",
    "    \"Special_Teams\": pd.DataFrame(),\n",
    "}\n",
    "\n",
    "# Get a list of all sub-folders\n",
    "sub_folders = [f.path for f in os.scandir(root_directory) if f.is_dir()]\n",
    "\n",
    "# Iterate through the sub-folders and search for CSV files\n",
    "for sub_folder in sub_folders:\n",
    "    category = os.path.basename(sub_folder)  # Extract the category from the folder name\n",
    "    \n",
    "    # Define the pattern to search for CSV files (e.g., all files with a .csv extension)\n",
    "    csv_pattern = os.path.join(sub_folder, \"*.csv\")\n",
    "    \n",
    "    # Use glob to find CSV files matching the pattern\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    \n",
    "    # Iterate through the CSV files in each category\n",
    "    for csv_file in csv_files:\n",
    "        player_name = os.path.basename(sub_folder)  # Extract the player name from the folder name\n",
    "        \n",
    "        # Use player_name to look up the player's position from player_bios\n",
    "        player_info = player_bios_df[player_bios_df[\"Player Name\"] == player_name]\n",
    "        if not player_info.empty:\n",
    "            player_position = player_info.iloc[0][\"Position\"]\n",
    "            \n",
    "            # Determine the unit (Offense, Defense, Special_Teams) based on the position\n",
    "            if player_position in offense_positions:\n",
    "                unit = \"Offense\"\n",
    "            elif player_position in defense_positions:\n",
    "                unit = \"Defense\"\n",
    "            elif player_position in special_teams_positions:\n",
    "                unit = \"Special_Teams\"\n",
    "            else:\n",
    "                unit = \"Unknown\"  # Handle positions not in the mapping\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Merge the DataFrame into the appropriate unit\n",
    "            merged_dataframes[unit] = pd.concat([merged_dataframes[unit], df], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Player '{player_name}' not found in player_bios.\")\n",
    "            \n",
    "# Now, the 'merged_dataframes' dictionary contains DataFrames merged by unit (e.g., \"Offense\", \"Defense\", \"Special_Teams\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_6872\\552861867.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Define the root directory where you want to search for sub-folders and CSV files\n",
    "root_directory = \"PlayerData\"  # Assuming \"PlayerData\" is in your current working directory\n",
    "\n",
    "# Get a list of all sub-folders\n",
    "sub_folders = [f.path for f in os.scandir(root_directory) if f.is_dir()]\n",
    "\n",
    "# Initialize a dictionary to store merged dataframes\n",
    "merged_dataframes = {}\n",
    "\n",
    "# Iterate through the sub-folders and search for CSV files\n",
    "for sub_folder in sub_folders:\n",
    "    # Define the pattern to search for CSV files (e.g., all files with a .csv extension)\n",
    "    csv_pattern = os.path.join(sub_folder, \"*.csv\")\n",
    "    \n",
    "    # Use glob to find CSV files matching the pattern\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    \n",
    "    # Iterate through the CSV files and merge them by filename\n",
    "    for csv_file in csv_files:\n",
    "        file_name = os.path.splitext(os.path.basename(csv_file))[0]  # Extract the filename without extension\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Check if a DataFrame with the same name already exists in the dictionary\n",
    "        if file_name in merged_dataframes:\n",
    "            # Append the data to the existing DataFrame\n",
    "            merged_dataframes[file_name] = pd.concat([merged_dataframes[file_name], df], ignore_index=True)\n",
    "        else:\n",
    "            # Create a new entry in the dictionary for the DataFrame\n",
    "            merged_dataframes[file_name] = df\n",
    "\n",
    "# Now, the 'merged_dataframes' dictionary contains DataFrames merged by filename.\n",
    "# You can access each merged DataFrame using the filename as the key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opponent</th>\n",
       "      <th>REC</th>\n",
       "      <th>YDS</th>\n",
       "      <th>AVG</th>\n",
       "      <th>TD</th>\n",
       "      <th>LNG</th>\n",
       "      <th>CAR</th>\n",
       "      <th>YDS.1</th>\n",
       "      <th>AVG.1</th>\n",
       "      <th>TD.1</th>\n",
       "      <th>...</th>\n",
       "      <th>RTG</th>\n",
       "      <th>1-19</th>\n",
       "      <th>20-29</th>\n",
       "      <th>30-39</th>\n",
       "      <th>40-49</th>\n",
       "      <th>50+</th>\n",
       "      <th>FG</th>\n",
       "      <th>FG%</th>\n",
       "      <th>XP</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vs MIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vs OAK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vs WAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vs OAK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vs WAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Opponent  REC   YDS  AVG   TD LNG  CAR  YDS.1  AVG.1  TD.1  ...  RTG  1-19  \\\n",
       "0   vs MIA  0.0   0.0  0.0  0.0   0  0.0    0.0    0.0   0.0  ...  NaN   NaN   \n",
       "1   vs OAK  5.0  34.0  6.8  0.0  15  0.0    0.0    0.0   0.0  ...  NaN   NaN   \n",
       "2   vs WAS  0.0   0.0  0.0  0.0   0  0.0    0.0    0.0   0.0  ...  NaN   NaN   \n",
       "3   vs OAK  NaN   0.0  0.0  0.0   0  NaN    NaN    NaN   NaN  ...  NaN   NaN   \n",
       "4   vs WAS  NaN   0.0  0.0  0.0   0  NaN    NaN    NaN   NaN  ...  NaN   NaN   \n",
       "\n",
       "   20-29 30-39  40-49  50+   FG  FG%   XP  PTS  \n",
       "0    NaN   NaN    NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1    NaN   NaN    NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2    NaN   NaN    NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3    NaN   NaN    NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4    NaN   NaN    NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataframes['Opponent'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
